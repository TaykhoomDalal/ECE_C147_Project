{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a126f97-6f5c-45eb-8082-1e5a99d7c064",
   "metadata": {},
   "source": [
    "# EEG Project Data Exploration\n",
    "\n",
    "EEG reflects the coordinated activity of millions of neurons near a non-invasive scalp electrode. Because these are scalp potentials, necessarily, they have relatively poor spatiotemporal resolution compared to other neural recording techniques. EEG is believed to be recording dipoles that are transmitted through the scalp.\n",
    "\n",
    "For each subject, they record from 22 EEG electrodes while the user imagines performing one of four actions. The four motor imagery tasks were: imagination of movement of the left hand (class 1), right hand (class 2), both feet (class 3), and tongue (class 4). Therefore, this is a classification task (with four outcome classes), where the EEG is used to determine what action the subject was imagining.\n",
    "\n",
    "The data was processed so that it is possible to load the data with numpy. Further, trials with NaN's have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff28aed-39f8-4d52-9f85-0f787121725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "import preprocessing\n",
    "import numpy as np\n",
    "import aug\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae0321e-da97-4088-baa6-669c80f880f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"../data/normalized/X_test.npy\")\n",
    "y_test = np.load(\"../data/normalized/y_test.npy\")\n",
    "person_test = np.load(\"../data/normalized/person_test.npy\")\n",
    "\n",
    "X_train_valid = np.load(\"../data/normalized/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"../data/normalized/y_train_valid.npy\")\n",
    "person_train_valid = np.load(\"../data/normalized/person_train_valid.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a49d0-d9a9-499f-a927-2354912cec3f",
   "metadata": {},
   "source": [
    "### Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836258e5-3248-430d-a21e-cb5baf749934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "print('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print('Test target shape: {}'.format(y_test.shape))\n",
    "print('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d423d32-54db-4a90-a818-199a50a7b57a",
   "metadata": {},
   "source": [
    "This indicates that there are 2115 trials; each trial has corresponding EEG data from 22 electrodes over 1000 time bins. Please look at the dataset documentation to know more about the data. E.g., Table 2 lists what class labels (769, 770, 771, 772) correspond to. The person files correspond to the subject performing the task, ranging from 0-8 (inclusive) and may be useful should you want to see how well you can classify on individual subjects. In the original data / documentation, you may see that there are 25 channels. We have removed 3 of the channels (so that there are 22) because those 3 channels were for recording eye movements, not brain activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c4025-2caa-4608-bee9-0d8566923faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class values\", np.unique(y_train_valid))\n",
    "print(\"Number of trials in each class\", np.bincount(y_train_valid - np.unique(y_train_valid)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f0711-a122-4195-bd96-2d8e14842ce4",
   "metadata": {},
   "source": [
    "769 == Cue onset left (class 1)  \n",
    "770 == Cue onset right (class 2)  \n",
    "771 == Cue onset foot (class 3)  \n",
    "772 == Cue onset tongue (class 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a21a3-2787-47f0-84ad-f0249223458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(X_train_valid[2, :, i], label='class 1') # trial 3, channel 1, across all time points \n",
    "    plt.plot(X_train_valid[7, :, i], label='class 2') # trial 8, channel 1, across all time points \n",
    "    plt.plot(X_train_valid[0, :, i], label='class 3') # trial 1, channel 1, across all time points \n",
    "    plt.plot(X_train_valid[1, :, i], label='class 4') # trial 2, channel 1, across all time points \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('EEG Signal of Channel %d' % (i+1))\n",
    "    plt.xlabel('Time bin')\n",
    "    plt.ylabel('Signal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy = aug.spawner(X_train_valid, y_train_valid)\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(X_noisy[2, :, i], label='class 1') # trial 3, channel 1, across all time points \n",
    "    plt.plot(X_noisy[7, :, i], label='class 2') # trial 8, channel 1, across all time points \n",
    "    plt.plot(X_noisy[0, :, i], label='class 3') # trial 1, channel 1, across all time points \n",
    "    plt.plot(X_noisy[1, :, i], label='class 4') # trial 2, channel 1, across all time points \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('EEG Signal of Channel %d' % (i+1))\n",
    "    plt.xlabel('Time bin')\n",
    "    plt.ylabel('Signal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b17a9-8f5e-4846-99b9-e42cf71edf56",
   "metadata": {},
   "source": [
    "Ideas to implement:  \n",
    "- subsampling because nearby time points have similar values  \n",
    "- trimming the last 600 time points away because there doesn't seem to be a difference in signal\n",
    "- regularization\n",
    "- larger convolutions are probably better \n",
    "- RNNs suffer from vanishing gradient problem, LSTM is solution to this - probably use bidirectional LSTM to encode temporal aspect of signal\n",
    "\n",
    "Optimizer: Adam  \n",
    "Loss Function: cross entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7121018d-9eb2-4408-8fbb-bc31b7eab08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1,2,3,4],\n",
    "              [0,1,2,3,4],\n",
    "              [0,1,2,3,4]])\n",
    "\n",
    "b = np.array([[0,0,0,0,0],\n",
    "              [1,1,1,1,1],\n",
    "              [2,2,2,2,2]])\n",
    "\n",
    "c = np.array([[0,0,0,0,0],\n",
    "              [1,1,1,1,1],\n",
    "              [2,2,2,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca3e130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(a, axis =1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d7c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [1, 1, 1],\n",
       "       [2, 2, 2],\n",
       "       [3, 3, 3],\n",
       "       [4, 4, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(a, (1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.stack((a,b,c), axis = 1)\n",
    "print(result.shape)\n",
    "result = result.reshape(result.shape[0] * result.shape[1], result.shape[2])\n",
    "print(result.shape)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = aug.gaussian_noise(X_train_valid, mean=0, std=0.5)\n",
    "Xte = aug.gaussian_noise(X_test, mean=0, std=0.5)\n",
    "\n",
    "Xtr = aug.trim_time(Xtr, 0, 500)\n",
    "Xte = aug.trim_time(Xte, 0, 500)\n",
    "\n",
    "Xtr =preprocessing.subsample(Xtr, 5)\n",
    "Xte = preprocessing.subsample(Xte, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy = aug.spawner(Xtr, y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.stack((Xtr, X_noisy), axis = 1)\n",
    "result = result.reshape(result.shape[0], result.shape[1] * result.shape[2], result.shape[3])\n",
    "# print(Xtr[0, 0, 0])\n",
    "# print(X_noisy[0,0,0])\n",
    "# result[0,1,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
