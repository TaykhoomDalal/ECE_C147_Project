---
# optimizer options
batch_size: 128
optimizer: 'SGD'
learning_rate: 0.1
momentum: 0.9
l2_reg: 0.00001
dropout: 0.2

# lr scheduler options
lr_milestones:
  - 125
  - 175
lr_gamma: 0.1

# training options
epochs: 250

# run options
gpu: 0
no_gpu: false
model: "LSTM"
dataset_root: "data/normalized/"
num_workers: 4
no_memory_pinning: false

# experimental options
no_clipping: false
wndsze: 2
sample_type: 'none'
sample_size: 125



# misc options
log_root: "logs/"
run_name: "template"


